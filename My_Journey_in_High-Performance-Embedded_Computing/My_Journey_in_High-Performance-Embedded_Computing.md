# My Journey in High-Performance Embedded Computing

<p align="center">
  <img src="My Journey in High-Performance Embedded Computing.png" alt="High-Performance Embedded Computing">
</p>

I began my career in on-board computing at [Eastman Kodak](https://www.kodak.com/), a company that evolved into ITT and later Exelis. Early on, I had the opportunity to serve as the Principal Investigator for Advanced DSP, where my work focused on positioning Exelis at the forefront of space-borne embedded computing. This marked the beginning of a career-long focus on high-performance embedded systems built to operate in some of the most demanding environments imaginable.

Building on that foundation, I soon found myself working on airborne platforms, applying [JPEG 2000](https://jpeg.org/jpeg2000/) imaging to real-time surveillance systems. This included developing and integrating advanced image compression for aircraft pods and [Predator/Reaper UAV](https://www.ga-asi.com/remotely-piloted-aircraft/mq-9a) payloads. These systems demanded not just raw performance, but efficient processing under strict SWaP constraints, where every watt and millisecond counted.

That airborne imaging work evolved into the development of multiple airborne platforms that leveraged heterogeneous computing architectures, integrating traditional processors with FPGA-based accelerators. One of the most ambitious efforts culminated in the design of a high-density processing platform built around a cluster of custom-developed [Intel Xeon](https://www.intel.com/content/www/us/en/products/details/processors/xeon.html) nodes. Each node featured quad Xeons, an embedded 10 Gigabit switched Ethernet fabric on the backplane, and [FMC](https://www.vita.com/fmc) sites capable of hosting 15-watt FPGA compute modules. The platform pushed the limits of airborne high-performance embedded computing and earned a nickname inspired by a natural disaster because when we powered it on, you needed hearing protection.

As part of that IR&D journey, my team also developed what became the world's fastest [JPEG 2000](https://jpeg.org/jpeg2000/) implementation in FPGA, a capability that played a critical role in securing the [Gorgon Stare](https://en.wikipedia.org/wiki/Gorgon_Stare) program. That program was directly enabled by our group's innovation and forward-leaning architecture work.

After stepping away from the aerospace sector for a few years, I returned to continue my work on airborne and space-borne HPEC systems. This time, my focus was on onboard processing and dissemination platforms. These systems were built around [Microchip PolarFire FPGAs](https://www.microchip.com/en-us/products/fpgas-and-plds/fpgas/polarfire-fpgas), [Xilinx](https://www.xilinx.com/) compute nodes, and radiation-hardened Microchip CPUs running [RTEMS](https://www.rtems.org/) and NASA's [Core Flight System (cFS)](https://cfs.gsfc.nasa.gov/) middleware. This blend of real-time embedded software, hardened hardware, and scalable software architecture echoed the themes that have carried through my career: high reliability, high performance, and mission-first design.

The system performed onboard processing of multiband imagery, compressing data in real-time and storing it in a custom-built flight recorder. Beyond storage, it also supported on-demand dissemination, enabling near-real-time access to acquired imagery while still in flight. This end-to-end pipeline, from sensor to storage to dissemination, embodied the complexity and responsiveness required of modern airborne and spaceborne ISR platforms.

Today, my interests lie in the use of [SYCL](https://www.khronos.org/sycl/) (pronounced "sickle"), which stands for "SYstem C Language." It is a modern C++-based programming paradigm for high-performance, heterogeneous computing developed by the Khronos Group. I see SYCL as a key enabler for future embedded systems, especially those deployed in space-borne platforms, where portability, performance, and determinism are critical. Using SYCL would allow designers and image scientists to develop algorithms, test and debug them, and then deploy them on various compute nodes that comprise the platform, whether it's a spacecraft, an airborne system, a ground station, or a tactical radio.

As I explore new opportunities, I'm particularly interested in applying SYCL to imaging (2D) and signal processing (1D) applications. From my experience, I see tremendous value for SIGINT applications, such as signal location identification with phased array antennas, source identification, and advanced phased array interference nulling techniques. The beauty of SYCL is that algorithms can be tested and deployed across various hardware platforms, allowing companies to reuse their IP in applications ranging from portable GPU/FPGA solutions to space-borne computing platforms.

I'd be interested to connect with others exploring SYCL for embedded applications or working on the next generation of high-performance computing for aerospace and defense. What technological advances are you most excited about in this space?